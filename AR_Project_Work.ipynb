{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize as w_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop_words = set(stopwords.words('english') + [\"...\"])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfv\n",
    "from sklearn.decomposition import NMF as nmf\n",
    "\n",
    "import pdfminer\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.high_level import extract_text\n",
    "import PyPDF2\n",
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1917\n",
      "20th_Century_Women\n",
      "BridgeofSpies\n",
      "ExMachina\n",
      "First_Reformed\n",
      "Get_Out\n",
      "GreenBook\n",
      "Hell_or_HighWater\n",
      "InsideOut\n",
      "KnivesOut\n",
      "LadyBird\n",
      "LaLaLand\n",
      "Manchester_By_TheSea\n",
      "MarriageStory\n",
      "Parasite\n",
      "Roma\n",
      "ShapeofWater\n",
      "Spotlight\n",
      "StraightOuttaCompton\n",
      "TheBigSick\n",
      "TheFavourite\n",
      "TheLobster\n",
      "ThreeBillboards\n",
      "Vice\n",
      "\n",
      "\n",
      "Sanity check for lists: True\n"
     ]
    }
   ],
   "source": [
    "# extract text from list of pdf titles and create dataframe of text\n",
    "\n",
    "path = './Scripts/'\n",
    "end = '.pdf'\n",
    "titles = ['1917', '20th_Century_Women', 'BridgeofSpies', 'ExMachina', 'First_Reformed',\n",
    "         'Get_Out', 'GreenBook', 'Hell_or_HighWater', 'InsideOut', 'KnivesOut', 'LadyBird',\n",
    "         'LaLaLand', 'Manchester_By_TheSea', 'MarriageStory', 'Parasite', 'Roma', \n",
    "          'ShapeofWater', 'Spotlight', 'StraightOuttaCompton', 'TheBigSick', \n",
    "         'TheFavourite', 'TheLobster', 'ThreeBillboards', 'Vice']\n",
    "\n",
    "movie_scripts = []\n",
    "for title in titles:\n",
    "    script = extract_text(path + title + end)\n",
    "    movie_scripts.append(script)\n",
    "    print (title)\n",
    "\n",
    "# create dataframe of scripts/titles from lists    \n",
    "movie_df = pd.DataFrame(list(zip(titles, movie_scripts)), columns = ['Title', 'Script'])\n",
    "\n",
    "# add label for original screenplay win, best picture win, and year\n",
    "orig_screen_win = [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "best_pic_win = ['Nom', None, 'Nom', None, None, 'Nom', 'Win', 'Nom', None, None, 'Nom', 'Nom', 'Nom', 'Nom', 'Win', 'Nom', 'Win', 'Win', None, None, 'Nom', None, 'Nom', 'Nom']\n",
    "year = [2019, 2016, 2015, 2015, 2018, 2017, 2018, 2016, 2015, 2019, 2017, 2016, 2016, 2019, 2019, 2018, 2017, 2015, 2015, 2017, 2018, 2016, 2017, 2018]\n",
    "reviewer = [\"Shafer\", \"Shafer\", \"Shafer\", \"Shafer\", \"Ragan\", \"Shafer\", \"Ragan\", \"Ragan\", \"Shafer\", \"Shafer\", \"Ragan\", \"Ragan\", \"Shafer\", \"Ragan\", \"Shafer\", \"Ragan\", \"Ragan\", \"Shafer\", \"Shafer\", \"Ragan\", \"Ragan\", \"Shafer\", \"Ragan\", \"Ragan\"]\n",
    "\n",
    "# sanity check -- should return True\n",
    "print(f\"\\n\\nSanity check for lists: {len(orig_screen_win) == len(year) == len(best_pic_win) ==  len(list(movie_df['Title'])) == len(reviewer)}\")\n",
    "\n",
    "movie_df['year'] = year\n",
    "movie_df['orig_screen_win'] = orig_screen_win\n",
    "movie_df['best_pic_win'] = best_pic_win\n",
    "movie_df['reviewer'] = reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column of dialogue\n",
    "# column of visual cues\n",
    "# column of setting\n",
    "# raw script column\n",
    "# everything column\n",
    "\n",
    "\n",
    "# corpus of just dialogue\n",
    "# corpus of everything (dialogue, settings, visual cues, etc.) cleaned up\n",
    "# corpus of visual cues\n",
    "\n",
    "# so 3 x per model\n",
    "    # sentiment analysis on dialogue (CV + TFIDF)\n",
    "    # sentiment analysis on everything (CV + TFIDF)\n",
    "    # sentimental analysis on visual cues\n",
    "    # and so on forth\n",
    "\n",
    "# POS tagging and keep only proper names and put rest into settings (when dialogue vs setting can both be caps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = movie_df[movie_df['reviewer'] == \"Ragan\"].copy()\n",
    "ar['CleanedScript'] = ar['Script']\n",
    "\n",
    "raw_scripts = list(ar['Script'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### semi-manually extract dialogue\n",
    "\n",
    "varies by script, easier to do it manually than write a function with 10k if statements that may still not capture everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_start(idx, todrop):\n",
    "    return raw_scripts[idx].replace(todrop, \"\")\n",
    "\n",
    "extraneous = [\"Scripts.com\\n\\nFirst Reformed\\n\\nBy Paul Schrader\\n\\nPage 1/57\\n\\n\\x0c\", \n",
    "              \"GREEN BOOK \\n\\nWritten by \\n\\nNick Vallelonga & Brian Currie & Peter Farrelly \\n\\n\\x0c\", \n",
    "              \"Scripts.com\\n\\nHell or High Water\\n\\nBy Taylor Sheridan\\n\\nPage 1/42\\n\\n\\x0c\", \n",
    "              \" \\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nLADY BIRD \\n\\nwritten by \\n\\nGreta Gerwig \\n\\n\\x0c \\n \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\nii. \\n\\n\", \n",
    "              \"LA LA LAND\\n\\nby\\n\\nDamien Chazelle\\n\\n\\x0c\", \n",
    "              \"MARRIAGE STORY\\n\\nWritten and Directed by Noah Baumbach\\n\\n\\x0cBlack.\\n\\n\", \n",
    "              \"IN ENGLISH\\n\\n\\x0cROMA\\n\\nWritten and Directed by\\n\\nAlfonso Cuarón\\n\\nDates in RED are meant only as a tool for the different departments for \\nthe specific historical accuracy of the scenes and are not intended to \\nappear on screen. \\n\\n\\x0cThursday, September 3rd, 1970\\n\\n\", \n",
    "              \"F O R   Y O U R   C O N S I D E R A T I O N\\n\\nB E S T   O R I G I N A L   S C R E E N P L A Y\\n\\nG U I L L E R M O   D E L   T O R O\\n&\\nV A N E S S A   T A Y L O R\\n\\n\\x0c1                             \\n\\n1\\n\\n\", \n",
    "              \"THE BIG SICK\\n\\nby\\nEmily V. Gordon & Kumail Nanjiani\\n\\n\\x0c1\\n\\n\", \n",
    "              \"F O R   Y O U R   C O N S I D E R A T I O N\\n\\nW R I T T E N   B Y\\n\\nD E B O R A H   D A V I S   A N D   T O N Y   M C N A M A R A\\n\\n\\x0cW R I T T E N   B Y\\n\\nD E B O R A H   D A V I S   A N D   T O N Y   M C N A M A R A\\n\\n\\x0cTHE FAVOURITE\\n\\nWritten by\\n\\nDeborah Davis and Tony McNamara\\n\\nFINAL SHOOTING SCRIPT - 23rd MARCH 2017\\n\\nElement Pictures\\n21 Mespil Road \\nDublin 4\\nIreland\\n\\nScarlet Films\\n3 Oakley Studios\\nUpper Cheyne Row\\nLondon SW3 5JW, UK\\n\\n \\n\\n\\x0c1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n\", \n",
    "              \"F O R   Y O U R   C O N S I D E R A T I O N\\n\\nB E S T   O R I G I N A L   S C R E E N P L A Y\\n\\nM A R T I N   M c D O N A G H\\n\\n\\x0cTHREE BILLBOARDS OUTSIDE EBBING, MISSOURI\\n\\nYou Red Welby?\\n\\nby\\nMartin McDonagh\\n\\n1\\n\\n\", \n",
    "              \"Written and Directed by\\n\\nVICE\\n\\nAdam McKay\\n\\n\\x0c\"]\n",
    "\n",
    "for r in range(len(raw_scripts)):\n",
    "    raw_scripts[r] = drop_start(r, extraneous[r])\n",
    "\n",
    "# expand contractions\n",
    "def expand_contractions(text):\n",
    "    text = re.sub(\"\\'s\", \" is\", text) # it's --> it is\n",
    "    text = re.sub(\"ain\\'t\", \"are not\", text) # ain't --> are not\n",
    "    text = re.sub(\"n\\'t\", \" not\", text) # don't --> do not\n",
    "    text = re.sub(\"\\'re\", \" are\", text) # you're --> you are\n",
    "    text = re.sub(\"\\'d\", \" would\", text) # she'd --> she would\n",
    "    text = re.sub(\"\\'ll\", \" will\", text) # he'll --> he will\n",
    "    text = re.sub(\"\\'ve\", \" have\", text) # we've --> we have\n",
    "    text = re.sub(\"\\'m\", \" am\", text) # I'm --> I am\n",
    "    return text\n",
    "\n",
    "for i in range(len(raw_scripts)):\n",
    "    raw_scripts[i] = expand_contractions(raw_scripts[i])\n",
    "\n",
    "# instantiate empty lists to become columns\n",
    "master_dialogue = []\n",
    "master_cleaned_everything = []\n",
    "\n",
    "def clean_lists(lis):\n",
    "    cust_punct = string.punctuation + \"`\" + \"'\" + \"’\" + \"”\" + \"“\" + \"...\"\n",
    "    if type(lis) != list:\n",
    "        lis = w_tokenize(lis)\n",
    "    lis = [l.replace(\"'\", \"\") for l in lis]\n",
    "    # strip punctuation\n",
    "    lis = [t for t in lis if t not in set(cust_punct)]\n",
    "    # lemmatize + lowercase\n",
    "    lis = [lemma.lemmatize(l) for l in lis]\n",
    "    # drop stop words\n",
    "    lis = [t for t in lis if t not in set(stop_words)]\n",
    "    # strip new lines\n",
    "    lis = [re.sub('\\s+', ' ', l) for l in lis]\n",
    "    # remove all non-alphanumeric -- fail safe code\n",
    "    lis = [re.sub(\"[^a-zA-Z0-9\\\\s]\", \"\", l) for l in lis]\n",
    "    return lis\n",
    "\n",
    "def split_dialogue_everything(script, pages):\n",
    "    first_ref = False\n",
    "    hhw = False\n",
    "    other = False\n",
    "    script = script.replace(\"'\", \"\")\n",
    "    if script == raw_scripts[0]:\n",
    "        first_ref = True\n",
    "    elif script == raw_scripts[2]:\n",
    "        hhw = True\n",
    "    else:\n",
    "        other = True\n",
    "    # remove page numbers\n",
    "    script = re.sub(pages, \" \", script)\n",
    "    # remove voiceover --(V.O.)--from script\n",
    "    script = script.replace(\"(V.O.)\", \"\")\n",
    "    # extract dialogue -- some require customization\n",
    "    # First Reformed\n",
    "    if first_ref:\n",
    "        print('First Reformed')\n",
    "        split_script = w_tokenize(script)\n",
    "        orig_split_script = split_script.copy()\n",
    "        # find indexes with (\n",
    "        open_pars = [i for i, e in enumerate(split_script) if e == \"(\"]\n",
    "        # find indexes with )\n",
    "        end_pars = [i for i, e in enumerate(split_script) if e == \")\"]\n",
    "        # return words between ( and ) to extract visual cues\n",
    "        visual_cues_fr = [\" \".join(split_script[open_pars[o]+1:end_pars[o]]) for o in range(len(open_pars))]\n",
    "        # drop visual cues from list\n",
    "        for o in range(len(open_pars)):\n",
    "            del split_script[open_pars[o]:end_pars[0]+1]\n",
    "        # re-join : with character names and drop extra :\n",
    "        # find indices with :\n",
    "        char_idx = [i for i, item in enumerate(split_script) if item.endswith(':')]\n",
    "        # for every index with :, go to the index before and add : to re-join CHARACTER with :\n",
    "        for b in char_idx:\n",
    "            split_script[b-1] = split_script[b-1] + split_script[b]\n",
    "        # drop extraneous colons\n",
    "        if \":\" in split_script:\n",
    "            split_script.remove(\":\")\n",
    "        # append non-character names to dialogue list\n",
    "        dialogue = [split_script[t] for t in range(len(split_script)) if split_script[t].endswith(\":\") == False]\n",
    "        script = orig_split_script\n",
    "    # Hell or High Water -- script is literally just dialogue\n",
    "    elif hhw:\n",
    "        print('Hell or High Water')\n",
    "        dialogue = script\n",
    "    # All others\n",
    "    else:\n",
    "        print('Others')\n",
    "        # split on combo of caps and new lines\n",
    "        split_script = re.split(\"\\\\n[A-Z]*\\s?\\\\n\", script)\n",
    "        visual_cues = []\n",
    "        # if begins with INT or EXT then it's a setting and the next line is visual cue\n",
    "        settings = [v for v in range(len(split_script)) if split_script[v].startswith(\"INT\")\n",
    "                    or split_script[v].startswith(\"EXT\")\n",
    "                    or split_script[v].startswith(\"VISUALS|VISUAL\")]\n",
    "        # extract visual cues\n",
    "        visual_cue = [split_script[s+1] for s in settings]\n",
    "        # remove word if uppercase\n",
    "        visual_cue = [w for w in visual_cue if w.isupper() == False]\n",
    "        visual_cues.append(visual_cue)\n",
    "        sets_cues_id = []\n",
    "        for s in settings:\n",
    "            sets_cues_id.append(s)\n",
    "            sets_cues_id.append(s+1)\n",
    "        # remove settings and visual cues from dialogue\n",
    "        dialogue_ms = [split_script[d] for d in range(len(split_script)) if d not in sets_cues_id]\n",
    "        # removing entries that are just all caps (i.e. CHARLIE)\n",
    "        dialogue_wo_upper = [d for d in dialogue_ms if d.isupper() == False]\n",
    "        # removing entries that don't have a character indicator\n",
    "        dialogue_wo_indicator = [t for t in dialogue_wo_upper if t[:3].isupper() == False]\n",
    "        # split out indicators from dialogue + flatten nested list\n",
    "        dialogue_split = [re.split(\"[A-Z]\\s?\\\\n\", t) for t in dialogue_wo_upper if t[:3].isupper()]\n",
    "        # drop indicator + flatten split list\n",
    "        dialogue_flatten = []\n",
    "        for ts in dialogue_split:\n",
    "            ts.pop(0)\n",
    "            dialogue_flatten.append(ts)\n",
    "        dialogue_flatten = [item for sublist in dialogue_flatten for item in sublist]\n",
    "        dialogue = dialogue_flatten + dialogue_wo_indicator\n",
    "    # clean + join lists\n",
    "    everything_list = \" \".join(clean_lists(script))\n",
    "    dialogue_list = \" \".join(clean_lists(dialogue))\n",
    "    # return everything list and dialogue list\n",
    "    return everything_list, dialogue_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process First Reformed\n",
    "\n",
    "`raw_scripts[0]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\t\n",
    "        Setting: none, script is just dialogue and a few visuals\t\n",
    "        Character: bold all caps:\t\n",
    "        Visual: (ALL CAPS)\n",
    "        Other Notes: some lines are randomly preceded by dashes and includes page numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_fr, dialogue_list_fr = split_dialogue_everything(raw_scripts[0], \n",
    "                                                                 \"\\\\nPage \\d+/57\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_fr)\n",
    "# master_cleaned_everything.append(everything_list_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Green Book\n",
    "\n",
    "`raw_scripts[1]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\n",
    "        Setting: bold and preceded by ext/int\n",
    "        Character: centered, all caps\t\n",
    "        Visual: block of text with some words in all caps for emphasis\t\n",
    "        Other Notes: page numbers sandwiched by CONTINUED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_gb, dialogue_list_gb = split_dialogue_everything(raw_scripts[1], \n",
    "                                                                 \"\\\\x0c                                   \\\\n\\\\n   \\d+\\.\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_gb)\n",
    "# master_cleaned_everything.append(everything_list_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Hell or High Water\n",
    "\n",
    "`raw_scripts[2]`\n",
    "\n",
    "        Speaking: a wall of text\n",
    "        Setting: none, script is just dialogue\n",
    "        Character: none, script is just dialogue\n",
    "        Visual: none, script is just dialogue\n",
    "        Other Notes: page numbers are marked (1/42, 2/42, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_hhw, dialogue_list_hhw = split_dialogue_everything(raw_scripts[2], \n",
    "                                                                       \"\\\\nPage \\d+/42\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Lady Bird\n",
    "\n",
    "`raw_scripts[3]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\n",
    "        Setting: preceded by ext/int in all caps\t\n",
    "        Character: centered, all caps\n",
    "        Visual: just words\t\n",
    "        Other Notes: very little extraneous text at beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_lb, dialogue_list_lb = split_dialogue_everything(raw_scripts[3], \n",
    "                                                                       \"\\\\x0c\\s?[\\\\n\\\\n ?\\\\n ?]+\\d+\\. ?\\\\n\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process La La Land\n",
    "\n",
    "`raw_scripts[4]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\n",
    "        Setting: words\t\n",
    "        Character: NAME\n",
    "        Visual: words, sometimes italcized or underlined\n",
    "        Other Notes: music titles are in brackets and bold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extraneous number lines/scene codes\n",
    "raw_scripts[4] = re.sub(\"\\\\n\\d+\\\\n\", \"\", raw_scripts[4])\n",
    "raw_scripts[4] = re.sub(\"\\\\n[A-Z]\\d+\\\\n\", \"\", raw_scripts[4])\n",
    "raw_scripts[4] = re.sub(\"\\[(.*?)\\]\", \"\", raw_scripts[4])\n",
    "\n",
    "# extract and process dialogue\n",
    "everything_list_lll, dialogue_list_lll = split_dialogue_everything(raw_scripts[4], \n",
    "                                                                       \"Revision\\\\n\\\\n\\d+\\.\\\\n\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Marriage Story\n",
    "\n",
    "`raw_scripts[5]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\n",
    "        Setting: preceded by ext/int in all caps\tcentered, all caps\t\n",
    "        Character: just words; pattern of character\n",
    "        Visual: name \\n dialogue \\n free text not preceeded by character name \\n and then character name \\n or new setting\t\n",
    "        Other Notes: N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_ms, dialogue_list_ms = split_dialogue_everything(raw_scripts[5], \n",
    "                                                                       \"\\\\x0c                                                 \\d+\\.\\\\n\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Roma\n",
    "\n",
    "`raw_scripts[6]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\t\n",
    "        Setting: preceded by ext/int in all caps\t\n",
    "        Character: centered, all caps\t\n",
    "        Visual: block of text\t\n",
    "        Other Notes: includes dates in red for design department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_r, dialogue_list_r = split_dialogue_everything(raw_scripts[6], \n",
    "                                                                       \"\\\\x0c\\d+\\.\\\\n\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Shape of Water\n",
    "\n",
    "`raw_scripts[7]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text, sometimes surrounded by quotes when character Dialogue is speaking\t\n",
    "        Setting: preceded by ext/int in all caps\t\n",
    "        Character: centered, all caps\t\n",
    "        Visual: text, sometimes italicized\t\n",
    "        Other Notes: extraneous details at the beginning \"for your consideration\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extraneous number lines/scene codes\n",
    "raw_scripts[7] = raw_scripts[7].replace(\"\\n\\nTHE SHAPE OF WATER\\nTHE SHAPE OF WATER\\nWritten by\\n\\nGuillermo del Toro\\nWritten by\\n&\\nVanessa Taylor\\nGuillermo del Toro\\n&\\nVanessa Taylor\\nStory by\\nGuillermo del Toro\\n\\nStory by\\nGuillermo del Toro\\n\\nFOX SEARCHLIGHT PICTURES, INC. \\n10201 W. Pico Blvd.\\nLos Angeles, CA 90035\\n\\nFOX SEARCHLIGHT PICTURES, INC. \\n10201 W. Pico Blvd.\\nLos Angeles, CA 90035\\n\\nALL RIGHTS RESERVED. COPYRIGHT ©2016 WILLOW AND OAK, INC. NO PORTION OF THIS SCRIPT MAY BE \\nPERFORMED, PUBLISHED, REPRODUCED, SOLD OR DISTRIBUTED BY ANY MEANS, OR QUOTED OR PUBLISHED IN ANY \\nMEDIUM, INCLUDING ANY WEB SITE, WITHOUT THE PRIOR WRITTEN CONSENT OF WILLOW AND OAK, INC. DISPOSAL \\nOF THIS SCRIPT COPY DOES NOT ALTER ANY OF THE RESTRICTIONS SET FORTH ABOVE.\\n\\nALL RIGHTS RESERVED. COPYRIGHT ©2016 WILLOW AND OAK, INC. NO PORTION OF THIS SCRIPT MAY BE \\nPERFORMED, PUBLISHED, REPRODUCED, SOLD OR DISTRIBUTED BY ANY MEANS, OR QUOTED OR PUBLISHED IN ANY \\nMEDIUM, INCLUDING ANY WEB SITE, WITHOUT THE PRIOR WRITTEN CONSENT OF WILLOW AND OAK, INC. DISPOSAL \\nOF THIS SCRIPT COPY DOES NOT ALTER ANY OF THE RESTRICTIONS SET FORTH ABOVE.\", \"\")\n",
    "raw_scripts[7] = re.sub(\"\\\\n\\d+\\\\n\", \"\", raw_scripts[7])\n",
    "raw_scripts[7] = re.sub(\"\\\\n[A-Z]\\d+\\\\n\", \"\", raw_scripts[7])\n",
    "\n",
    "# extract and process dialogue\n",
    "everything_list_sow, dialogue_list_sow = split_dialogue_everything(raw_scripts[7], \n",
    "                                                                       \"\\\\x0c\\d+                             \\\\n\\\\n\\d+\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process The Big Sick\n",
    "\n",
    "`raw_scripts[8]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\t\n",
    "        Setting: preceded by ext/int in all caps\t\n",
    "        Character: centered, all caps\t\n",
    "        Visual: just words; pattern of character name \\n dialogue \\n free text not preceeded by character name \\n and then character name \\n or new setting\t\n",
    "        Other Notes: (V.O.) means voiceover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_tbs, dialogue_list_tbs = split_dialogue_everything(raw_scripts[8], \n",
    "                                                                       \"\\\\n\\\\x0c\\d+\\\\n\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process The Favourite\n",
    "\n",
    "`raw_scripts[9]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text\t\n",
    "        Setting: preceded by ext/int in all caps and surrounded by numbers\t\n",
    "        Character: centered, all caps\t\n",
    "        Visual: preceded by setting and number\t\n",
    "        Other Notes: preceding extraneous details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extraneous number lines/scene codes\n",
    "raw_scripts[9] = re.sub(\"\\\\n\\d+\\\\n\", \"\", raw_scripts[9])\n",
    "\n",
    "# extract and process dialogue\n",
    "everything_list_tf, dialogue_list_tf = split_dialogue_everything(raw_scripts[9], \n",
    "                                                                       \"\\\\x0cTHE FAVOURITE SHOOTING SCRIPT 6 MAR 17   \\d+.\\\\n\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Three Billboards\n",
    "\n",
    "`raw_scripts[10]`\n",
    "\n",
    "        Speaking: all caps NAME \\n text, sometimes words are randomly underlined\t\n",
    "        Setting: bold and preceded by ext/int\t\n",
    "        Character: bold centered, all caps\t\n",
    "        Visual: words\t\n",
    "        Other Notes: extraneous details at the beginning \"for your consideration\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extraneous number lines/scene codes\n",
    "raw_scripts[10] = re.sub(\"\\\\n\\d+\\\\n\", \"\", raw_scripts[10])\n",
    "\n",
    "# extract and process dialogue\n",
    "everything_list_tb, dialogue_list_tb = split_dialogue_everything(raw_scripts[10], \n",
    "                                                                       \"\\\\n\\d+\\.\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### process Vice\n",
    "\n",
    "`raw_scripts[11]`\n",
    "\n",
    "        Speaking: voiceovers are in quotes but regular dialogue is all caps NAME \\n text\t\n",
    "        Setting: preceded by ext/int in all caps\t\n",
    "        Character: centered, all caps\t\n",
    "        Visual: some visual cues are in all caps for emphasis \"POLICE LIGHTS FLASH behind him as he drives\" and stage directions i.e. (into his ear piece) are in ()\n",
    "        Other Notes: (V.O.) means voiceover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n"
     ]
    }
   ],
   "source": [
    "# extract and process dialogue\n",
    "everything_list_v, dialogue_list_v = split_dialogue_everything(raw_scripts[11], \n",
    "                                                                       \"\\\\x0c\\d+\\.\\\\n\")\n",
    "\n",
    "# # append to master lists\n",
    "# master_dialogue.append(dialogue_list_MOVIE)\n",
    "# master_cleaned_everything.append(everything_list_MOVIE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### return processed scripts to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity checks\n",
    "# len(master_dialogue) == 12\n",
    "# len(master_visual_cues) == 12\n",
    "# len(master_cleaned_everything) == 12\n",
    "\n",
    "# # make column of dialogue\n",
    "# ar['dialogue'] = master_dialogue\n",
    "\n",
    "# # make column of visual cues\n",
    "# ar['visual_cues'] = master_visual_cues\n",
    "\n",
    "# # make everything column\n",
    "# ar['cleaned_script'] = master_cleaned_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP transformations\n",
    "\n",
    "CV + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "maybe one person uses ANEW and one uses Harvard-IV??\n",
    "\n",
    "or just split it up so one person does: \n",
    "- SA with dialogue CV \n",
    "- SA with dialogue TFIDF\n",
    "\n",
    "and the other does:\n",
    "- SA with everything CV\n",
    "- SA with everything TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling -- AS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering  -- AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
