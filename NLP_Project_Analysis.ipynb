{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Makes A Best Original Screenplay?\n",
    "\n",
    "    By Allison Ragan and Allison Shafer\n",
    "    American University\n",
    "    STAT-696 Applied Natural Language Processing\n",
    "\n",
    "# Objective\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "    I. Package Imports\n",
    "    II. NLP Transformations\n",
    "        i. CountVectorized\n",
    "        ii. TFIDF\n",
    "    III. Sentiment Analysis\n",
    "        i. Sentiment Analysis -- Dialogue\n",
    "        ii. Sentiment Analysis -- Full Script\n",
    "    IV. Topic Modeling\n",
    "        i. Topic Modeling -- Dialogue\n",
    "        ii. Topic Modeling -- Full Script\n",
    "    V. K-Means Clustering\n",
    "        i. K-Means Clustering -- Dialogue\n",
    "        ii. K-Means Clustering -- Full Script\n",
    "    VI. Results\n",
    "    VII. Deprecated Code\n",
    "\n",
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in .csv to dataframe\n",
    "\n",
    "movies_df = pd.read_csv('./movies_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP transformations\n",
    "\n",
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "bow_all = CountVectorizer(ngram_range=(1,2))\n",
    "# fit + transform training data\n",
    "bow_all_fit = bow_all.fit_transform(movies_df['cleaned_script'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "tfidf_all = TfidfVectorizer(max_features=5000)\n",
    "# fit + transform training data\n",
    "tfidf_all_fit = tfidf_all.fit_transform(movies_df['cleaned_script'])\n",
    "tfidf_vocab_all = tfidf_dialogue.vocabulary_\n",
    "tfidf_vocab_all = {k: v for k, v in sorted(tfidf_vocab_all.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(tfidf_vocab_all)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "tfidf_dialogue = TfidfVectorizer(max_features=5000)\n",
    "# fit + transform training data\n",
    "tfidf_dialogue_fit = tfidf_dialogue.fit_transform(movies_df['cleaned_dialogue'])\n",
    "tfidf_vocab_dialogue = tfidf_dialogue.vocabulary_\n",
    "tfidf_vocab_dialogue = {k: v for k, v in sorted(tfidf_vocab_dialogue.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(tfidf_vocab_dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "maybe one person uses ANEW and one uses Harvard-IV??\n",
    "\n",
    "or just split it up so one person does: \n",
    "- SA with dialogue CV \n",
    "\n",
    "and the other does:\n",
    "- SA with everything CV\n",
    "\n",
    "### Sentiment Analysis -- Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis -- Full Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling -- AS\n",
    "\n",
    "TFIDF\n",
    "\n",
    "### Topic Modeling -- Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling -- Full Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering  -- AR\n",
    "\n",
    "Either on CV and TFIDF, or just on NMF\n",
    "\n",
    "### K Means Clustering -- Dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Means Clustering -- Full Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from homework 6\n",
    "\n",
    "# def eval_k(kmeans, centroids, terms):\n",
    "#     cluster_terms = []\n",
    "#     for i in range(kmeans.n_clusters):\n",
    "#         termss = []\n",
    "#         for ind in centroids[i, :10]:\n",
    "#             termss.append(terms[ind])\n",
    "#         cluster_terms.append(termss)\n",
    "#     for i in range(kmeans.n_clusters):\n",
    "#         print(f'\\tCluster {i+1}: {\" \".join(cluster_terms[i])}')\n",
    "\n",
    "# # K-Means with a) Count Vectorized\n",
    "# k_cv = KMeans(n_clusters = 20, random_state = 0).fit(cv_tf)\n",
    "# k_cv_centroids = k_cv.cluster_centers_.argsort()[:, ::-1]\n",
    "# k_cv_terms = cv_feat_names\n",
    "# k_cv_labels = k_cv.labels_\n",
    "\n",
    "# print(\"Count Vectorized:\")\n",
    "# eval_k(k_cv, k_cv_centroids, k_cv_terms)\n",
    "\n",
    "# # K-Means with b) TFIDF\n",
    "# k_tfidf = KMeans(n_clusters = 20, random_state = 0).fit(tfidf)\n",
    "# k_tfidf_centroids = k_tfidf.cluster_centers_.argsort()[:, ::-1]\n",
    "# k_tfidf_terms = cv_feat_names\n",
    "# k_tfidf_labels = k_tfidf.labels_\n",
    "\n",
    "# print(\"TFIDF:\")\n",
    "# eval_k(k_tfidf, k_tfidf_centroids, k_tfidf_terms)\n",
    "\n",
    "# # K-Means with c) NMF -- (1,1), (1,2), (2,3) based on 4\n",
    "# k_nmf = KMeans(n_clusters = 20, random_state = 0).fit(tfidf_onetwo_matrix)\n",
    "# k_nmf_centroids = k_nmf.cluster_centers_.argsort()[:, ::-1]\n",
    "# k_nmf_terms = tfidf_onetwo_feat_names\n",
    "# k_nmf_labels = k_nmf.labels_\n",
    "\n",
    "# print(\"NMF:\")\n",
    "# eval_k(k_nmf, k_nmf_centroids, k_nmf_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
